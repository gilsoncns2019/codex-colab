{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Processador de Conte√∫do Multi-Agente com Gemini API no Google Colab\n",
    "\n",
    "Este notebook permite processar conte√∫do textual utilizando um sistema de agentes especializados, impulsionado pela API Gemini do Google. Ele oferece suporte a m√∫ltiplas chaves de API para redund√¢ncia e permite a montagem do Google Drive para acesso e salvamento de arquivos.\n",
    "\n",
    "## ‚ú® Funcionalidades\n",
    "\n",
    "- **Processamento Multi-Agente**: Utiliza agentes especializados (Transcritor/Extrator, Estruturador/Visualizador, Especialista em LaTeX, Formatador Obsidian) para transformar conte√∫do bruto em notas formatadas para Obsidian.\n",
    "- **API Gemini**: Integra√ß√£o com a API Gemini para tarefas de processamento de linguagem natural, como estrutura√ß√£o e revis√£o.\n",
    "- **M√∫ltiplas Chaves API**: Gerenciamento autom√°tico de m√∫ltiplas chaves de API para maior robustez e resili√™ncia contra falhas ou limites de uso.\n",
    "- **Montagem do Google Drive**: Acesso direto a arquivos armazenados no seu Google Drive.\n",
    "- **Configura√ß√£o Flex√≠vel**: Permite ao usu√°rio especificar o arquivo de entrada, o caminho de sa√≠da e os modelos Gemini a serem utilizados por cada agente.\n",
    "\n",
    "## üõ†Ô∏è Configura√ß√£o Inicial\n",
    "\n",
    "### 1. Instalar Depend√™ncias\n",
    "\n",
    "Execute a c√©lula abaixo para instalar as bibliotecas necess√°rias, incluindo a SDK do Google Gemini.\n",
    "\n",
    "```python\n",
    "%pip install -q -U google-generativeai\n",
    "%pip install -q -U ipywidgets\n",
    "```\n",
    "\n",
    "### 2. Montar Google Drive\n",
    "\n",
    "Execute a c√©lula abaixo para montar seu Google Drive. Isso permitir√° que o notebook acesse arquivos do seu Drive e salve os resultados l√°.\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "```\n",
    "\n",
    "### 3. Configurar Chaves da API Gemini\n",
    "\n",
    "Insira suas chaves da API Gemini na lista abaixo. Voc√™ pode obter suas chaves em [Google AI Studio](https://aistudio.google.com/app/apikey). √â recomend√°vel usar m√∫ltiplas chaves para evitar limites de taxa.\n",
    "\n",
    "```python\n",
    "# @param {type: \"string\"} api_key_1\n",
    "# @param {type: \"string\"} api_key_2\n",
    "# @param {type: \"string\"} api_key_3\n",
    "# @param {type: \"string\"} api_key_4\n",
    "# @param {type: \"string\"} api_key_5\n",
    "\n",
    "api_keys = [\n",
    "    api_key_1, \n",
    "    api_key_2, \n",
    "    api_key_3, \n",
    "    api_key_4, \n",
    "    api_key_5\n",
    "]\n",
    "\n",
    "# Filtra chaves vazias ou nulas\n",
    "api_keys = [key for key in api_keys if key and key.strip() != \"\"]\n",
    "\n",
    "if not api_keys:\n",
    "    raise ValueError(\"Nenhuma chave API Gemini fornecida. Por favor, insira pelo menos uma chave.\")\n",
    "\n",
    "print(f\"{len(api_keys)} chave(s) API configurada(s).\")\n",
    "```\n",
    "\n",
    "### 4. Definir Caminhos de Arquivo\n",
    "\n",
    "Especifique o caminho completo para o arquivo de entrada (o conte√∫do bruto a ser processado) e o diret√≥rio onde o arquivo Markdown final ser√° salvo.\n",
    "\n",
    "```python\n",
    "# @param {type: \"string\"} input_file_path\n",
    "# @param {type: \"string\"} output_directory\n",
    "\n",
    "input_file_path = \"/content/drive/MyDrive/meu_conteudo.txt\" # Exemplo: /content/drive/MyDrive/meu_conteudo.txt\n",
    "output_directory = \"/content/drive/MyDrive/NotasObsidian\" # Exemplo: /content/drive/MyDrive/NotasObsidian\n",
    "output_filename = \"nota_processada.md\" # Nome do arquivo de sa√≠da\n",
    "\n",
    "import os\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "output_file_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "print(f\"Arquivo de entrada: {input_file_path}\")\n",
    "print(f\"Arquivo de sa√≠da ser√° salvo em: {output_file_path}\")\n",
    "```\n",
    "\n",
    "### 5. Configurar Modelos Gemini (Opcional)\n",
    "\n",
    "Voc√™ pode especificar modelos Gemini diferentes para cada agente, ou usar o modelo padr√£o (`gemini-pro`) para todos. Isso pode ser √∫til para otimizar o desempenho ou a qualidade para tarefas espec√≠ficas.\n",
    "\n",
    "```python\n",
    "# @param {type: \"string\"} transcriber_model\n",
    "# @param {type: \"string\"} structurer_model\n",
    "# @param {type: \"string\"} latex_model\n",
    "# @param {type: \"string\"} formatter_model\n",
    "\n",
    "model_names = {\n",
    "    \"TranscriberExtractorAgent\": transcriber_model if transcriber_model else \"gemini-pro\",\n",
    "    \"StructurerVisualizerAgent\": structurer_model if structurer_model else \"gemini-pro\",\n",
    "    \"LatexExpertAgent\": latex_model if latex_model else \"gemini-pro\",\n",
    "    \"ObsidianFormatterAgent\": formatter_model if formatter_model else \"gemini-pro\"\n",
    "}\n",
    "\n",
    "print(\"Configura√ß√£o de Modelos Gemini por Agente:\")\n",
    "for agent, model in model_names.items():\n",
    "    print(f\"- {agent}: {model}\")\n",
    "```\n",
    "\n",
    "## ‚öôÔ∏è Execu√ß√£o do Processamento\n",
    "\n",
    "### 1. Carregar M√≥dulos do Sistema\n",
    "\n",
    "Esta c√©lula cria os arquivos Python necess√°rios (`api_manager.py` e `agents_enhanced.py`) diretamente no ambiente do Colab. Isso garante que as classes e fun√ß√µes estejam dispon√≠veis para importa√ß√£o e execu√ß√£o.\n",
    "\n",
    "```python\n",
    "%%writefile api_manager.py\n",
    "import random\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class GeminiAPIManager:\n",
    "    \"\"\"\n",
    "    Gerenciador de m√∫ltiplas chaves da API Gemini para redund√¢ncia e balanceamento de carga.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_keys: List[str]):\n",
    "        \"\"\"\n",
    "        Inicializa o gerenciador com uma lista de chaves API.\n",
    "        \n",
    "        Args:\n",
    "            api_keys: Lista de chaves da API Gemini\n",
    "        \"\"\"\n",
    "        if not api_keys:\n",
    "            raise ValueError(\"Pelo menos uma chave API deve ser fornecida\")\n",
    "        \n",
    "        self.api_keys = api_keys\n",
    "        self.current_key_index = 0\n",
    "        self.failed_keys = set()\n",
    "        self.retry_count = {}\n",
    "        self.max_retries = 3\n",
    "        self.retry_delay = 1\n",
    "        \n",
    "    def get_next_key(self) -> Optional[str]:\n",
    "        available_keys = [key for key in self.api_keys if key not in self.failed_keys]\n",
    "        \n",
    "        if not available_keys:\n",
    "            self.failed_keys.clear()\n",
    "            self.retry_count.clear()\n",
    "            available_keys = self.api_keys\n",
    "            \n",
    "        if not available_keys:\n",
    "            return None\n",
    "            \n",
    "        key = available_keys[self.current_key_index % len(available_keys)]\n",
    "        self.current_key_index = (self.current_key_index + 1) % len(available_keys)\n",
    "        \n",
    "        return key\n",
    "    \n",
    "    def mark_key_failed(self, api_key: str):\n",
    "        self.retry_count[api_key] = self.retry_count.get(api_key, 0) + 1\n",
    "        \n",
    "        if self.retry_count[api_key] >= self.max_retries:\n",
    "            self.failed_keys.add(api_key)\n",
    "            print(f\"‚ö†Ô∏è Chave API marcada como falhada ap√≥s {self.max_retries} tentativas\")\n",
    "    \n",
    "    def configure_genai(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "    \n",
    "    def create_model(self, model_name: str = \"gemini-pro\") -> Optional[genai.GenerativeModel]:\n",
    "        for attempt in range(len(self.api_keys) + 1):\n",
    "            api_key = self.get_next_key()\n",
    "            \n",
    "            if not api_key:\n",
    "                print(\"‚ùå Todas as chaves API falharam\")\n",
    "                return None\n",
    "            \n",
    "            try:\n",
    "                self.configure_genai(api_key)\n",
    "                model = genai.GenerativeModel(model_name)\n",
    "                test_response = model.generate_content(\"Teste\")\n",
    "                \n",
    "                print(f\"‚úÖ Chave API configurada com sucesso (modelo: {model_name})\")\n",
    "                return model\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Falha na chave API: {str(e)}\")\n",
    "                self.mark_key_failed(api_key)\n",
    "                \n",
    "                if attempt < len(self.api_keys):\n",
    "                    print(f\"üîÑ Tentando pr√≥xima chave... (tentativa {attempt + 1})\")\n",
    "                    time.sleep(self.retry_delay)\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def generate_content_with_fallback(self, prompt: str, model_name: str = \"gemini-pro\", max_attempts: int = None) -> Optional[str]:\n",
    "        if max_attempts is None:\n",
    "            max_attempts = len(self.api_keys)\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            api_key = self.get_next_key()\n",
    "            \n",
    "            if not api_key:\n",
    "                print(\"‚ùå Nenhuma chave API dispon√≠vel\")\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                self.configure_genai(api_key)\n",
    "                model = genai.GenerativeModel(model_name)\n",
    "                response = model.generate_content(prompt)\n",
    "                \n",
    "                print(f\"‚úÖ Conte√∫do gerado com sucesso (tentativa {attempt + 1})\")\n",
    "                return response.text\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erro na tentativa {attempt + 1}: {str(e)}\")\n",
    "                self.mark_key_failed(api_key)\n",
    "                \n",
    "                if attempt < max_attempts - 1:\n",
    "                    print(f\"üîÑ Tentando pr√≥xima chave...\")\n",
    "                    time.sleep(self.retry_delay)\n",
    "        \n",
    "        print(\"‚ùå Todas as tentativas falharam\")\n",
    "        return None\n",
    "    \n",
    "    def get_status(self) -> Dict:\n",
    "        return {\n",
    "            \"total_keys\": len(self.api_keys),\n",
    "            \"failed_keys\": len(self.failed_keys),\n",
    "            \"available_keys\": len(self.api_keys) - len(self.failed_keys),\n",
    "            \"current_key_index\": self.current_key_index,\n",
    "            \"retry_counts\": self.retry_count.copy()\n",
    "        }\n",
    "\n",
    "class EnhancedAgent:\n",
    "    def __init__(self, name: str, prompt: str, api_manager: GeminiAPIManager, model_name: str = \"gemini-pro\"):\n",
    "        self.name = name\n",
    "        self.prompt = prompt\n",
    "        self.api_manager = api_manager\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "    \n",
    "    def ensure_model(self):\n",
    "        if not self.model:\n",
    "            self.model = self.api_manager.create_model(self.model_name)\n",
    "            \n",
    "        if not self.model:\n",
    "            raise RuntimeError(f\"N√£o foi poss√≠vel configurar o modelo para o agente {self.name}\")\n",
    "    \n",
    "    def process_with_gemini(self, content_to_process: str) -> str:\n",
    "        full_prompt = f\"{self.prompt}\\n\\nConte√∫do a ser processado: {content_to_process}\"\n",
    "        \n",
    "        response = self.api_manager.generate_content_with_fallback(\n",
    "            prompt=full_prompt,\n",
    "            model_name=self.model_name\n",
    "        )\n",
    "        \n",
    "        if not response:\n",
    "            raise RuntimeError(f\"Falha ao processar conte√∫do no agente {self.name}\")\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def process(self, content):\n",
    "        raise NotImplementedError\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "%%writefile agents_enhanced.py\n",
    "import re\n",
    "import time # Importar time para usar time.strftime\n",
    "from api_manager import GeminiAPIManager, EnhancedAgent\n",
    "\n",
    "class TranscriberExtractorAgent(EnhancedAgent):\n",
    "    def __init__(self, api_manager: GeminiAPIManager, model_name: str = \"gemini-pro\"):\n",
    "        prompt = \"\"\"\n",
    "        Voc√™ √© o Agente 1: Transcritor/Extrator de Conte√∫do. Sua fun√ß√£o √© realizar a transcri√ß√£o fiel de √°udios/v√≠deos ou a extra√ß√£o precisa de texto de PDFs/slides. Voc√™ n√£o interpreta, resume ou opina, apenas captura a mat√©ria-prima. Sua sa√≠da deve manter a fidelidade ao conte√∫do original, incluindo quest√µes de revis√£o e gabaritos.\n",
    "        \n",
    "        Instru√ß√µes espec√≠ficas:\n",
    "        - Mantenha a fidelidade absoluta ao conte√∫do original\n",
    "        - N√£o remova informa√ß√µes importantes\n",
    "        - Preserve quest√µes, gabaritos e coment√°rios\n",
    "        - Identifique e marque claramente bizus e dicas\n",
    "        \"\"\"\n",
    "        super().__init__(\"Transcritor/Extrator de Conte√∫do\", prompt, api_manager, model_name)\n",
    "\n",
    "    def process(self, content):\n",
    "        processed_content = content\n",
    "        bizus = []\n",
    "        questions = []\n",
    "\n",
    "        patterns_to_remove = [\n",
    "            r\"(?is)Apresenta√ß√£o do Curso.*?(?=\\n\\n|\\Z)\",\n",
    "            r\"(?is)Sum√°rio.*?(?=\\n\\n|\\Z)\",\n",
    "            r\"(?is)√çndice.*?(?=\\n\\n|\\Z)\",\n",
    "            r\"(?is)Conte√∫do Introdut√≥rio e Administrativo.*?(?=\\n\\n|\\Z)\",\n",
    "            r\"(?is)Material Publicit√°rio.*?(?=\\n\\n|\\Z)\",\n",
    "            r\"(?is)Metadados de Origem.*?(?=\\n\\n|\\Z)\",\n",
    "            r\"(?i)P√°gina \\d+\",\n",
    "            r\"(?i)Direitos Autorais ¬© \\d{4}\",\n",
    "            r\"(?is)Se√ß√µes de Exerc√≠cios.*?(?=\\n\\n|\\Z)\",\n",
    "            r\"(?is)Exerc√≠cios N√£o Comentados/Resolvidos.*?(?=\\n\\n|\\Z)\",\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns_to_remove:\n",
    "            processed_content = re.sub(pattern, \n",
    "                                       lambda m: \"\" if \"Quest√£o\" not in m.group(0) and \"Gabarito\" not in m.group(0) else m.group(0),\n",
    "                                       processed_content)\n",
    "\n",
    "        bizu_pattern = r\"(?i)(bizu\\s*[:!].*?(?:\\n|$))\"\n",
    "        bizu_matches = list(re.finditer(bizu_pattern, processed_content))\n",
    "        \n",
    "        for match in reversed(bizu_matches):\n",
    "            bizus.append(match.group(0).strip())\n",
    "            processed_content = processed_content[:match.start()] + processed_content[match.end():]\n",
    "        bizus.reverse()\n",
    "\n",
    "        if len(processed_content) > 1000:\n",
    "            try:\n",
    "                ai_bizus = self.process_with_gemini(f\"Identifique dicas, macetes ou bizus importantes no seguinte texto. Retorne apenas as dicas encontradas, uma por linha: {processed_content}\")\n",
    "                if ai_bizus and ai_bizus.strip():\n",
    "                    for line in ai_bizus.strip().split(\'\\n\'):\n",
    "                        if line.strip() and line.strip() not in [b.strip() for b in bizus]:\n",
    "                            bizus.append(f\"Bizu: {line.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erro ao processar bizus com IA: {e}\")\n",
    "\n",
    "        question_pattern = r\"(?is)(Quest√£o\\s*\\d*\\s*\\(.*?\\).*?(?:Alternativa\\s*[A-Z]\\).*?)*Gabarito\\s*[:!].*?Coment√°rio\\s*[:!].*?(?:\\n\\n|\\Z))\"\n",
    "        question_matches = list(re.finditer(question_pattern, processed_content))\n",
    "\n",
    "        for match in reversed(question_matches):\n",
    "            questions.append(match.group(0).strip())\n",
    "            processed_content = processed_content[:match.start()] + processed_content[match.end():]\n",
    "        questions.reverse()\n",
    "\n",
    "        return {\n",
    "            \"main_content\": processed_content.strip(),\n",
    "            \"bizus\": bizus,\n",
    "            \"questions\": questions\n",
    "        }\n",
    "\n",
    "class StructurerVisualizerAgent(EnhancedAgent):\n",
    "    def __init__(self, api_manager: GeminiAPIManager, model_name: str = \"gemini-pro\"):\n",
    "        prompt = \"\"\"\n",
    "        Voc√™ √© o Agente 2: Estruturador e Visualizador. Sua fun√ß√£o √© organizar o conte√∫do bruto em uma estrutura l√≥gica de Markdown, aplicando heur√≠sticas de visualiza√ß√£o para decidir qual diagrama (Mermaid) √© mais apropriado para cada tipo de informa√ß√£o.\n",
    "        \n",
    "        Instru√ß√µes espec√≠ficas:\n",
    "        - Organize o conte√∫do em se√ß√µes claras e hier√°rquicas\n",
    "        - Use formata√ß√£o Markdown apropriada (t√≠tulos, listas, √™nfases)\n",
    "        - Sugira diagramas Mermaid quando apropriado\n",
    "        - Mantenha a legibilidade e navegabilidade\n",
    "        - Preserve toda a informa√ß√£o importante\n",
    "        \"\"\"\n",
    "        super().__init__(\"Estruturador e Visualizador\", prompt, api_manager, model_name)\n",
    "\n",
    "    def process(self, extracted_data):\n",
    "        main_content = extracted_data.get(\'main_content\', \'\')\n",
    "        bizus = extracted_data.get(\'bizus\', [])\n",
    "        questions = extracted_data.get(\'questions\', [])\n",
    "\n",
    "        structured_content = \"# Conte√∫do Estruturado\\n\\n\"\n",
    "        \n",
    "        if main_content:\n",
    "            structured_content += \"## Conte√∫do Principal\\n\\n\"\n",
    "            \n",
    "            if len(main_content) > 500:\n",
    "                try:\n",
    "                    ai_structured = self.process_with_gemini(f\"\"\"\\n",
    "                    Estruture o seguinte conte√∫do em Markdown bem organizado:\n",
    "                    - Use t√≠tulos e subt√≠tulos apropriados (##, ###)\n",
    "                    - Crie listas quando apropriado\n",
    "                    - Mantenha par√°grafos bem formatados\n",
    "                    - Preserve toda a informa√ß√£o original\n",
    "                    - N√£o adicione informa√ß√µes que n√£o est√£o no texto original\n",
    "                    \n",
    "                    Conte√∫do: {main_content}\n",
    "                    \"\"\")\n",
    "                    structured_content += ai_structured + \"\\n\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Erro ao estruturar com IA, usando conte√∫do original: {e}\")\n",
    "                    structured_content += main_content + \"\\n\\n\"\n",
    "            else:\n",
    "                structured_content += main_content + \"\\n\\n\"\n",
    "        \n",
    "        if bizus:\n",
    "            structured_content += \"## üí° Bizus e Dicas Importantes\\n\\n\"\n",
    "            for i, bizu in enumerate(bizus, 1):\n",
    "                clean_bizu = bizu.replace(\"Bizu:\", \"\").replace(\"bizu:\", \"\").strip()\n",
    "                structured_content += f\"> [!TIP] **Bizu {i}:** {clean_bizu}\\n\\n\"\n",
    "        \n",
    "        if questions:\n",
    "            structured_content += \"## üìù Quest√µes de Revis√£o\\n\\n\"\n",
    "            for i, question_text in enumerate(questions, 1):\n",
    "                try:\n",
    "                    formatted_question = self.process_with_gemini(f\"\"\"\\n",
    "                    Formate a seguinte quest√£o em Markdown bem estruturado:\n",
    "                    - Separe claramente o enunciado, alternativas, gabarito e coment√°rio\n",
    "                    - Use formata√ß√£o apropriada para cada se√ß√£o\n",
    "                    - Mantenha toda a informa√ß√£o original\n",
    "                    \n",
    "                    Quest√£o: {question_text}\n",
    "                    \"\"\")\n",
    "                    structured_content += f\"### Quest√£o {i}\\n\\n{formatted_question}\\n\\n---\\n\\n\"\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Erro ao formatar quest√£o com IA: {e}\")\n",
    "                    question_parts_match = re.search(r\"(?is)(Quest√£o\\s*\\d*\\s*\\(.*?\\).*?(?:Alternativa\\s*[A-Z]\\).*?)*Gabarito\\s*[:!].*?Coment√°rio\\s*[:!].*?(?:\\n\\n|\\Z))\", question_text)\n",
    "                    \n",
    "                    if question_parts_match:\n",
    "                        q_body = question_parts_match.group(1).strip()\n",
    "                        alternatives_raw = question_parts_match.group(2).strip()\n",
    "                        gabarito = question_parts_match.group(3).strip()\n",
    "                        comentario = question_parts_match.group(4).strip()\n",
    "\n",
    "                        structured_content += f\"### Quest√£o {i}\\n\\n\"\n",
    "                        structured_content += f\"{q_body}\\n\\n\"\n",
    "                        \n",
    "                        formatted_alternatives = []\n",
    "                        for alt_line in alternatives_raw.split(\'\\n\'):\n",
    "                            if alt_line.strip():\n",
    "                                formatted_alternatives.append(f\"- [ ] {alt_line.strip()}\")\n",
    "                        structured_content += \'\\n\'.join(formatted_alternatives) + \"\\n\\n\"\n",
    "                        \n",
    "                        structured_content += f\"**{gabarito}**\\n\\n\"\n",
    "                        structured_content += f\"**{comentario}**\\n\\n\"\n",
    "                        structured_content += f\"---\\n\\n\"\n",
    "                    else:\n",
    "                        structured_content += f\"### Quest√£o {i}\\n\\n{question_text}\\n\\n---\\n\\n\"\n",
    "\n",
    "        try:\n",
    "            diagram_suggestion = self.process_with_gemini(f\"\"\"\\n",
    "            Analise o seguinte conte√∫do e determine se seria √∫til adicionar um diagrama Mermaid.\n",
    "            Se sim, especifique o tipo (flowchart, sequenceDiagram, graph, mindmap, etc.) e forne√ßa o c√≥digo Mermaid.\n",
    "            Se n√£o for apropriado, responda apenas \'Nenhum diagrama necess√°rio\'.\n",
    "            \n",
    "            Conte√∫do: {main_content[:1000]}\n",
    "            \"\"\")\n",
    "            \n",
    "            if \'mermaid\' in diagram_suggestion.lower() and \'nenhum\' not in diagram_suggestion.lower():\n",
    "                structured_content += \"## üìä Diagrama Ilustrativo\\n\\n\"\n",
    "                structured_content += diagram_suggestion + \"\\n\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erro ao gerar diagrama: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"structured_content\": structured_content,\n",
    "            \"has_math\": \'$\' in main_content or \'f√≥rmula\' in main_content.lower() or \'equa√ß√£o\' in main_content.lower()\n",
    "        }\n",
    "\n",
    "class LatexExpertAgent(EnhancedAgent):\n",
    "    def __init__(self, api_manager: GeminiAPIManager, model_name: str = \"gemini-pro\"):\n",
    "        prompt = \"\"\"\n",
    "        Voc√™ √© o Agente 3: Especialista em LaTeX. Sua fun√ß√£o √© auxiliar na gera√ß√£o de c√≥digo LaTeX para f√≥rmulas e express√µes matem√°ticas, garantindo que a sintaxe esteja correta e seja compat√≠vel com o MathJax do Obsidian.\n",
    "        \n",
    "        Instru√ß√µes espec√≠ficas:\n",
    "        - Valide e corrija sintaxe LaTeX\n",
    "        - Garanta compatibilidade com MathJax\n",
    "        - Use $...$ para f√≥rmulas inline\n",
    "        - Use $$...$$ para f√≥rmulas em bloco\n",
    "        - Mantenha formata√ß√£o clara e leg√≠vel\n",
    "        \"\"\"\n",
    "        super().__init__(\"Especialista em LaTeX\", prompt, api_manager, model_name)\n",
    "\n",
    "    def process(self, structured_data):\n",
    "        structured_content = structured_data.get(\'structured_content\', \'\')\n",
    "        has_math = structured_data.get(\'has_math\', False)\n",
    "\n",
    "        if has_math:\n",
    "            try:\n",
    "                latex_improved = self.process_with_gemini(f\"\"\"\\n",
    "                Revise e melhore a sintaxe LaTeX no seguinte texto:\n",
    "                - Corrija erros de sintaxe LaTeX\n",
    "                - Garanta compatibilidade com MathJax do Obsidian\n",
    "                - Mantenha f√≥rmulas inline com $...$ e em bloco com $$...$$\n",
    "                - N√£o altere o conte√∫do n√£o-matem√°tico\n",
    "                - Retorne o texto completo com as corre√ß√µes\n",
    "                \n",
    "                Texto: {structured_content}\n",
    "                \"\"\")\n",
    "                structured_content = latex_improved\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erro ao processar LaTeX com IA: {e}\")\n",
    "                structured_content = re.sub(r\"\\$([^$]+?)\\$?\", r\"$\1$\", structured_content)\n",
    "                structured_content = re.sub(r\"\\$\$([^$]+?)\\$?\", r\"$$\1$$\", structured_content)\n",
    "            \n",
    "            structured_content += \"\\n> [!NOTE] üßÆ Este conte√∫do cont√©m f√≥rmulas matem√°ticas renderizadas com LaTeX/MathJax.\\n\\n\"\n",
    "\n",
    "        return {\n",
    "            \"content\": structured_content,\n",
    "            \"latex_processed\": has_math\n",
    "        }\n",
    "\n",
    "class ObsidianFormatterAgent(EnhancedAgent):\n",
    "    def __init__(self, api_manager: GeminiAPIManager, model_name: str = \"gemini-pro\"):\n",
    "        prompt = \"\"\"\n",
    "        Voc√™ √© o Agente 4: Formatador Final Obsidian. Sua fun√ß√£o √© revisar a nota completa para garantir que toda a formata√ß√£o Markdown esteja correta, que os links internos e externos funcionem, e que a nota seja clara, naveg√°vel e otimizada para o uso no Obsidian.\n",
    "        \n",
    "        Instru√ß√µes espec√≠ficas:\n",
    "        - Revise toda a formata√ß√£o Markdown\n",
    "        - Adicione tags relevantes e √∫teis\n",
    "        - Garanta navegabilidade e clareza\n",
    "        - Otimize para uso no Obsidian\n",
    "        - Mantenha consist√™ncia na formata√ß√£o\n",
    "        \"\"\"\n",
    "        super().__init__(\"Formatador Final Obsidian\", prompt, api_manager, model_name)\n",
    "\n",
    "    def process(self, latex_data):\n",
    "        content = latex_data.get(\'content\', \'\')\n",
    "        latex_processed = latex_data.get(\'latex_processed\', False)\n",
    "\n",
    "        try:\n",
    "            final_review = self.process_with_gemini(f\"\"\"\\n",
    "            Fa√ßa uma revis√£o final desta nota para Obsidian:\n",
    "            - Corrija qualquer problema de formata√ß√£o Markdown\n",
    "            - Adicione tags relevantes no final (formato: tags: [tag1, tag2, tag3])\n",
    "            - Garanta que t√≠tulos est√£o bem hierarquizados\n",
    "            - Verifique se listas e formata√ß√µes est√£o corretas\n",
    "            - Mantenha todo o conte√∫do original\n",
    "            - Retorne apenas o conte√∫do revisado, sem coment√°rios adicionais\n",
    "            \n",
    "            Nota: {content}\n",
    "            \"\"\")\n",
    "            \n",
    "            final_content = final_review\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erro na revis√£o final com IA: {e}\")\n",
    "            final_content = content\n",
    "            \n",
    "            if latex_processed and \"tags:\" not in final_content.lower():\n",
    "                final_content += \"\\n---\\ntags: [matem√°tica, latex, estudo]\\n\"\n",
    "\n",
    "        if not final_content.startswith(\"---\"):\n",
    "            metadata = f\"---\\ncreated: {time.strftime(\'%Y-%m-%d\')}\\ntags: [processado, multi-agente]\\n---\\n\\n\"\n",
    "            final_content = metadata + final_content\n",
    "\n",
    "        return final_content\n",
    "\n",
    "def process_content_with_enhanced_agents(raw_content, api_keys, model_names=None):\n",
    "    if model_names is None:\n",
    "        model_names = {\n",
    "            \"TranscriberExtractorAgent\": \"gemini-pro\",\n",
    "            \"StructurerVisualizerAgent\": \"gemini-pro\",\n",
    "            \"LatexExpertAgent\": \"gemini-pro\",\n",
    "            \"ObsidianFormatterAgent\": \"gemini-pro\"\n",
    "        }\n",
    "\n",
    "    api_manager = GeminiAPIManager(api_keys)\n",
    "    \n",
    "    transcriber = TranscriberExtractorAgent(api_manager, model_names.get(\'TranscriberExtractorAgent\'))\n",
    "    structurer = StructurerVisualizerAgent(api_manager, model_names.get(\'StructurerVisualizerAgent\'))\n",
    "    latex_expert = LatexExpertAgent(api_manager, model_names.get(\'LatexExpertAgent\'))\n",
    "    formatter = ObsidianFormatterAgent(api_manager, model_names.get(\'ObsidianFormatterAgent\'))\n",
    "\n",
    "    print(f\"\\nüöÄ Iniciando Processamento Multi-Agente com Gemini API\")\n",
    "    print(f\"üìä Status inicial: {api_manager.get_status()}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"\\nüîÑ Executando Agente 1: {transcriber.name}\")\n",
    "        extracted_data = transcriber.process(raw_content)\n",
    "        print(f\"‚úÖ Agente 1 conclu√≠do\")\n",
    "\n",
    "        print(f\"\\nüîÑ Executando Agente 2: {structurer.name}\")\n",
    "        structured_data = structurer.process(extracted_data)\n",
    "        print(f\"‚úÖ Agente 2 conclu√≠do\")\n",
    "\n",
    "        print(f\"\\nüîÑ Executando Agente 3: {latex_expert.name}\")\n",
    "        latex_data = latex_expert.process(structured_data)\n",
    "        print(f\"‚úÖ Agente 3 conclu√≠do\")\n",
    "\n",
    "        print(f\"\\nüîÑ Executando Agente 4: {formatter.name}\")\n",
    "        final_note = formatter.process(latex_data)\n",
    "        print(f\"‚úÖ Agente 4 conclu√≠do\")\n",
    "\n",
    "        print(f\"\\nüéâ Processamento Multi-Agente Conclu√≠do com Sucesso!\")\n",
    "        print(f\"üìä Status final: {api_manager.get_status()}\")\n",
    "        \n",
    "        return final_note\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro durante o processamento: {e}\")\n",
    "        print(f\"üìä Status no momento do erro: {api_manager.get_status()}\")\n",
    "        raise\n",
    "\n",
    "```\n",
    "\n",
    "### 2. Ler Conte√∫do do Arquivo de Entrada\n",
    "\n",
    "Esta c√©lula l√™ o conte√∫do do arquivo especificado em `input_file_path`. Certifique-se de que o caminho est√° correto e que voc√™ tem permiss√£o de acesso ao arquivo.\n",
    "\n",
    "```python\n",
    "try:\n",
    "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_content = f.read()\n",
    "    print(f\"Conte√∫do do arquivo \\'{input_file_path}\\' lido com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O arquivo \\'{input_file_path}\\' n√£o foi encontrado. Verifique o caminho.\")\n",
    "    raw_content = \"\" # Define como vazio para evitar erros subsequentes\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo: {e}\")\n",
    "    raw_content = \"\"\n",
    "\n",
    "# Exibe uma pr√©via do conte√∫do lido\n",
    "print(\"\nPr√©via do Conte√∫do Bruto (primeiros 500 caracteres):\")\n",
    "print(raw_content[:500] + (\"...\" if len(raw_content) > 500 else \"\"))\n",
    "```\n",
    "\n",
    "### 3. Executar Processamento Multi-Agente\n",
    "\n",
    "Esta √© a c√©lula principal que orquestra o processamento do conte√∫do usando os agentes configurados e suas respectivas chaves e modelos Gemini.\n",
    "\n",
    "```python\n",
    "from agents_enhanced import process_content_with_enhanced_agents\n",
    "\n",
    "if raw_content:\n",
    "    try:\n",
    "        final_processed_note = process_content_with_enhanced_agents(\n",
    "            raw_content, \n",
    "            api_keys, \n",
    "            model_names\n",
    "        )\n",
    "        print(\"\n‚úÖ Processamento conclu√≠do! Pr√©via da nota final:\")\n",
    "        print(final_processed_note[:1000] + (\"...\" if len(final_processed_note) > 1000 else \"\"))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Ocorreu um erro durante o processamento: {e}\")\n",
    "        final_processed_note = \"\"\n",
    "else:\n",
    "    print(\"N√£o h√° conte√∫do para processar. Verifique o arquivo de entrada.\")\n",
    "    final_processed_note = \"\"\n",
    "```\n",
    "\n",
    "### 4. Salvar Nota Final no Google Drive\n",
    "\n",
    "A nota processada ser√° salva no caminho especificado em `output_file_path` dentro do seu Google Drive.\n",
    "\n",
    "```python\n",
    "if final_processed_note:\n",
    "    try:\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_processed_note)\n",
    "        print(f\"\nüéâ Nota final salva com sucesso em: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao salvar a nota final: {e}\")\n",
    "else:\n",
    "    print(\"N√£o h√° nota final para salvar.\")\n",
    "```\n"
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}


